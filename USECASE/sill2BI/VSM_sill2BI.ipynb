{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"VSM_logo.gif\" width=\"500\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Campi Flegrei caldera (Italy) \n",
    "\n",
    "## 2011-2013 InSAR and GNSS modelling\n",
    "\n",
    "**VSM - Volcanic and Seismic source Modelling** is a Python code to perform inversions of geodetic data.\n",
    "\n",
    "**Code** https://github.com/EliTras/VSM \\\n",
    "**License** E. Trasatti - INGV (elisa.trasatti@ingv.it), covered by GNU-GPL License https://github.com/EliTras/VSM/blob/main/license.lic\n",
    "\n",
    "This Notebook contains details on the use of VSM to run data inversion, and post-processing\n",
    "\n",
    "Details of the run\n",
    "- Analytical forward model: sill-like source\n",
    "- Sampling algorithm: Bayesian Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path of the working folder\n",
    "folder_inout = './'\n",
    "filename_in = 'VSM_input_sill.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data\n",
    "Input data may be either displacements (m) or velocities (m/yr). If more than an input file is considered, of course the unit must be the same (all displacements or all velocities). For all datapoints, *East* and *North* are the coordinates (metric, preferred system is projected UTM).\n",
    "Accepted data types are\n",
    "- InSAR\n",
    "- GNSS\n",
    "- Levelling\n",
    "- EDM\n",
    "- Tilt\n",
    "- Strain\n",
    "\n",
    "### InSAR\n",
    "This data refers to InSAR data, both single inferterograms or multi-temporal InSAR. Results are typycally in terms of cumulative displacements or annual velocities. The InSAR maps are usually made of thounsands of pixels so it is needed to downsample the dataset first. VSM uses downsampled InSAR datasets.\n",
    "- up to 10 datasets from different sensors or missions\n",
    "- a single data file is referred as ` path/sarfile.txt `\n",
    "- for multiple datasets just leave a blank between fullpath names ` path/sarfile1.txt path/sarfile2.txt `\n",
    "- accepted formats are comma separated file (.csv), plain text (.txt), ESRI Shapefile (.shp). Ascii files may come with or without header in the first line\n",
    "- format of columns\n",
    "       East North Data Error LOS_E LOS_N LOS_Z\n",
    "       \n",
    "where *LOS_E*, *LOS_N*, *LOS_Z* are the East, North and vertical components of the versor of the Line of Sight of the sensor.\n",
    "\n",
    "### GNSS\n",
    "GNSS data are typically composed of mean velocity for each component of each benchmark.\n",
    "- the data file is referred to with ` path/gpsfile.txt `\n",
    "- accepted formats are comma separated files (.csv), plain text (.txt), ESRI Shapefiles (.shp). Ascii files may come with or without header in the first line\n",
    "- one row for each station\n",
    "- format of columns\n",
    "       East North Data_E Data_N Data_Z Error_E Error_N Error_Z\n",
    "\n",
    "where *Data_E* is the East component of the displacement or velocity. Same applies to the North (N) and vertical (Z) components and to the error associated.\n",
    "\n",
    "### Levelling\n",
    "Levelling data consists of differences of the elevation of benchmarks in a given time window.\n",
    "- the data file is referred to with ` path/levfile.txt `\n",
    "- accepted formats are comma separated files (.csv), plain text (.txt), ESRI Shapefiles (.shp). Ascii files may come with or without header in the first line\n",
    "- format of columns\n",
    "       East North Data Error\n",
    "\n",
    "where *Data* is the different of elevation in the given time period.\n",
    "\n",
    "### EDM\n",
    "EDM (Electro-optical Distance Measuring) technique measures the difference in the horizontal position between two points. - the file is referred to with ` path/edmfile.txt `\n",
    "- accepted formats are comma separated files (.csv), plain text (.txt), ESRI Shapefiles (.shp). Ascii files may come with or without header in the first line\n",
    "- format of columns\n",
    "       East1 North1 East2 North2 Data Error\n",
    "\n",
    "Each row has the coordinates of the start (1) and end (2) benchmark. *Data* is one single value, that is the change in distance in a given time period.\n",
    "\n",
    "### Tilt\n",
    "Tilt is a measure of the displacement-gradient. In particular, it is the inclination of the vertical along a horizontal direction. The horizontal derivatives of the vertical deformation correspond to the East and North components of tilt. \n",
    "- the file is referred to with ` path/tiltfile.txt `\n",
    "- accepted formats are comma separated files (.csv), plain text (.txt), ESRI Shapefiles (.shp). Ascii files may come with or without header in the first line\n",
    "- format of columns\n",
    "       East North Data_E Data_N Error_E Error_N\n",
    "\n",
    "Each row contains *Data* along East (E) and North (N) directions, and the associated error. If the tiltmeter is not oriented along East or North, data should be projected accordingly. Tilt is adimensional and the unit for VSM is microradians (ppm).\n",
    "\n",
    "### Strain\n",
    "Strain is a measure of the displacement-gradient. The volumetric strain is the unit change in volume, i.e. it combines the change of the displacement in the three components. \n",
    "- the file is referred to with ` path/strainfile.txt `\n",
    "- accepted formats are comma separated files (.csv), plain text (.txt), ESRI Shapefiles (.shp). Ascii files may come with or without header in the first line\n",
    "- format of columns\n",
    "       East North Data Error\n",
    "\n",
    "Strain *Data* is adimensional and the unit for VSM is microstrains (ppm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the input files. By default all file names are 'None'. Set to 'None those unused'\n",
    "\n",
    "# SAR filename(s)\n",
    "sar_file = '../DATA/obs_sar1.txt ../DATA/obs_sar2.txt'\n",
    "#GNSS filename\n",
    "gps_file = '../DATA/GPS_data.txt'\n",
    "# levelling filename\n",
    "lev_file = 'None'\n",
    "# EDM filename\n",
    "edm_file = 'None'\n",
    "#tilt filename\n",
    "tlt_file = 'None'\n",
    "# strain filename\n",
    "srn_file = 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAR weight\n",
    "sar_weight = 1.\n",
    "# GNSS weight\n",
    "gps_weight = 5.\n",
    "# levelling weight\n",
    "lev_weight = 0.\n",
    "# EDM weight\n",
    "edm_weight = 0.\n",
    "# tilt weight\n",
    "tlt_weight = 0.\n",
    "# strain weight\n",
    "srn_weight = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(os.path.join(folder_inout,filename_in), \"w\")\n",
    "f.write(folder_inout+'\\n')\n",
    "f.write(sar_file+'\\n'+gps_file+'\\n'+lev_file+'\\n'+edm_file+'\\n'+tlt_file+'\\n'+srn_file+'\\n')\n",
    "f.write(str(sar_weight)+'\\n'+str(gps_weight)+'\\n'+str(lev_weight)+'\\n'+str(edm_weight)+'\\n'+str(tlt_weight)+'\\n'+str(srn_weight)+'\\n');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# shear modulus (Pa)\n",
    "mu = 5e9\n",
    "# Poisson ratio\n",
    "ni = 0.25\n",
    "\n",
    "# number of sources\n",
    "num_sources = 1\n",
    "\n",
    "# write this part in the input file\n",
    "f.write(str(mu)+'\\n')\n",
    "f.write(str(ni)+'\\n')\n",
    "f.write(str(num_sources)+'\\n');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of forward model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mogi Point Source\n",
    "**Model 0** The Mogi (1958) point source model represents an isotropic point source. Parameters:\n",
    "- East coordinate of the source center\n",
    "- North coordinate of the source center\n",
    "- Depth of the source source center\n",
    "- Volume variation\n",
    "\n",
    "#### Mogi Finite Volume\n",
    "**Model 1** The McTigue (1987) finite volume model is an evolution of the Mogi model and represents a spherical source with finite volume. Parameters:\n",
    "- East coordinate of the source center\n",
    "- North coordinate of the source center\n",
    "- Depth of the source center\n",
    "- Radius of the sphere\n",
    "- $\\Delta P/ \\mu$ (Overpressure vs shear modulus ratio)\n",
    "\n",
    "#### Penny-shaped crack\n",
    "**Model 2** The penny shaped crack (Fialko et al., 2001) is a disk with a radius and no vertical extension. Parameters:\n",
    "- East coordinate of the disk center\n",
    "- North coordinate of the disk center\n",
    "- Depth of the disk center\n",
    "- Radius of the disk\n",
    "- $\\Delta P/ \\mu$ (Overpressure vs shear modulus ratio)\n",
    "\n",
    "#### Spheroid\n",
    "**Model 3** The spheroid (Yang et al., 1988) is a finite-volume cavity with a constant overpressure on the boundary. It can be arbitrarily oriented in space Parameters:\n",
    "- East coordinate of the source center\n",
    "- North coordinate of the source center\n",
    "- Depth of the source center\n",
    "- Semi-major axis\n",
    "- Ratio of semi-minor vs semi-major axes\n",
    "- $\\Delta P/ \\mu$ (Overpressure vs shear modulus ratio)\n",
    "- Strike angle\n",
    "- Dip angle\n",
    "\n",
    "#### Ellipsoid\n",
    "**Model 4** The ellipsoid (Davis, 1986) is a point source defined by its equivalent combination of dipoles and double forces. The P$_{ij}$ matrix must be defined, whose diagonal elements are the dipoles, while the off-diagonal are the double-forces according to catersian coordinates. The results must be interpreted following Davis (1986) tables to find the shape of the ellipsoid and its orientation. Parameters:\n",
    "- East coordinate of the source center\n",
    "- North coordinate of the source center\n",
    "- Depth of the source center\n",
    "- P$_{xx}$\n",
    "- P$_{yy}$\n",
    "- P$_{zz}$\n",
    "- P$_{xy}$\n",
    "- P$_{yz}$\n",
    "- P$_{zx}$\n",
    "\n",
    "#### Fault or Dike\n",
    "**Model 5** The fault model (Okada, 1985) is a rectangular plane undergoing shear slip and/or tensile opening/closing. Two configurations are available. The first uses strike-slip and dip-slip on the fault, while the other uses the total slip and the rake angle. Parameters:\n",
    "- East coordinate of the top left corner\n",
    "- North coordinate of the top left corner\n",
    "- Depth of the top\n",
    "- Length\n",
    "- Width\n",
    "- Strike angle\n",
    "- Dip angle\n",
    "- Strike-slip, or, conversely, total slip\n",
    "- Dip-slip, or, conversely, rake angle\n",
    "- Tensile movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the source identifier of the forward model\n",
    "# 0=Mogi 1=McTigue 2=Sill 3=Spheroid 4=Ellipsoid 5=Fault/Dike\n",
    "# comment or uncomment the lines needed, based on the number of sources employed\n",
    "sorg_identifier = 2\n",
    "#parameters minimum and maximum (minimum <= maximum)\n",
    "param1 = (422000., 432000.)\n",
    "param2 = (4515000., 4525000.)\n",
    "param3 = (2000., 7000.)\n",
    "param4 = (1000., 1000.)\n",
    "param5 = (1e-4, 1e-2)\n",
    "bounds = [param1,param2,param3,param4,param5]\n",
    "\n",
    "#Uncomment and define the style ('S' or 'R') in case of Okada (Fault/Dike source)\n",
    "#okada_mode = 'S'\n",
    "\n",
    "# write this part in the input file\n",
    "if(sorg_identifier!= 5):\n",
    "    f.write(str(sorg_identifier)+'\\n')\n",
    "else:\n",
    "    f.write(str(sorg_identifier)+' '+okada_mode+'\\n')\n",
    "       \n",
    "for k in range(len(bounds)):\n",
    "    row = str(list(bounds[k])[0])+'\\t'+str(list(bounds[k])[1])+'\\n'\n",
    "    f.write(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## VSM settings\n",
    "\n",
    "### Inversion algorithms\n",
    "There are two inversion tools included in VSM\n",
    "- **NA** is the **Neighbourhood Algorithm**, a global optimizer based on the Voronoi cells theory for the sampling (Sambridge, 1999). The parameters needed are:\n",
    "    - number of samples at each iteration `sampl1`\n",
    "    - number of re-samples from each iteration `sampl2`\n",
    "    - number of iterations `sampl3`\n",
    "- **BI** is the **Bayesian Inference**, an inversion tool based on the Bayes theory and MCMC sampling. The parameters needed are:\n",
    "    - number of random walks `sampl1`\n",
    "    - number of steps for each random walk `sampl2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inversion choice NA = 0 BI = 1\n",
    "inversion_choice = 1\n",
    "# accordingly define the sampling parameters\n",
    "sampl1 = 8\n",
    "sampl2 = 8000\n",
    "\n",
    "f.write(str(inversion_choice)+'\\n')\n",
    "if(inversion_choice == 0):\n",
    "    f.write(str(sampl1)+' '+str(sampl2)+'\\n')\n",
    "    f.write(str(sampl3)+'\\n')\n",
    "else:\n",
    "    f.write(str(sampl1)+'\\n')\n",
    "    f.write(str(sampl2)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of burn-in models. Default is 2000. No plots for -1\n",
    "num_skip = 2000\n",
    "f.write(str(num_skip)+'\\n');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END of settings for the VSM input!\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch VSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../VSM')\n",
    "\n",
    "import VSM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read VSM input\n",
    "VSM.read_VSM_settings(os.path.join(folder_inout,filename_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run VSM\n",
    "VSM.iVSM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import VSM_utilities as VSMU\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data, model and residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_file = 'VSM_synth_sar1.csv'\n",
    "out_file = 'VSM_res_sar1.png'\n",
    "\n",
    "# UTM zone\n",
    "zone = 33\n",
    "southern_hemisphere = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# My data in UTM coordinates\n",
    "db_sar = pd.read_csv(folder_inout+'/'+synth_file)\n",
    "d_sar = db_sar.values\n",
    "\n",
    "# Split into east and north coordinates\n",
    "east, north = d_sar[:,0],d_sar[:,1]\n",
    "data = d_sar[:,3]\n",
    "synth = d_sar[:,2]\n",
    "res = data - synth\n",
    "\n",
    "dmax = max(max(data),max(synth))\n",
    "dmin = min(min(data),min(synth))\n",
    "resmax = max(res)\n",
    "resmin = min(res)\n",
    "resext = max(resmax, -resmin)\n",
    "\n",
    "# Define the projection\n",
    "#crs=ccrs.PlateCarree()\n",
    "mycrs=ccrs.UTM(zone=zone, southern_hemisphere=southern_hemisphere)\n",
    "\n",
    "fig=plt.figure(figsize=(15,6))\n",
    "\n",
    "## PANEL DATA ##########\n",
    "ax = plt.subplot(131, projection=mycrs)\n",
    "ax.coastlines(resolution='10m')\n",
    "img = ax.scatter(east, north,5, data, cmap=\"RdYlBu_r\", vmin=dmin, vmax = dmax)\n",
    "#palette\n",
    "cbar = plt.colorbar(img,orientation='horizontal')\n",
    "cbar.set_label('LOS (m)')\n",
    "# Get the extent of the axis\n",
    "extent = ax.get_extent()\n",
    "# Attempt to set the axis extent\n",
    "ax.set_extent(extent, crs=mycrs)\n",
    "plt.title('Data',fontsize = 16, pad=10)\n",
    "\n",
    "## PANEL MODEL ##########\n",
    "ax = plt.subplot(132, projection=mycrs)\n",
    "ax.coastlines(resolution='10m')\n",
    "img = ax.scatter(east, north,5, synth,cmap=\"RdYlBu_r\", vmin=dmin, vmax = dmax)\n",
    "#palette\n",
    "cbar = plt.colorbar(img,orientation='horizontal')\n",
    "cbar.set_label('LOS (m)')\n",
    "# Get the extent of the axis\n",
    "extent = ax.get_extent()\n",
    "# Attempt to set the axis extent\n",
    "ax.set_extent(extent, crs=mycrs)\n",
    "plt.title('Model',fontsize = 16, pad=10)\n",
    "\n",
    "## PANEL RESIDUALS ##########\n",
    "ax = plt.subplot(133, projection=mycrs)\n",
    "ax.coastlines(resolution='10m')\n",
    "img = ax.scatter(east, north,5, data - synth,cmap=\"bwr\",vmin=resext, vmax = -resext)\n",
    "#palette\n",
    "cbar = plt.colorbar(img,orientation='horizontal')\n",
    "cbar.set_label('LOS (m)')\n",
    "# Get the extent of the axis\n",
    "extent = ax.get_extent()\n",
    "# Attempt to set the axis extent\n",
    "ax.set_extent(extent, crs=mycrs)\n",
    "# Title for plot\n",
    "plt.title('Residual',fontsize = 16, pad=10)\n",
    "\n",
    "plt.savefig(folder_inout+'/'+out_file)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_file = 'VSM_synth_sar2.csv'\n",
    "out_file = 'VSM_res_sar2.png'\n",
    "\n",
    "# UTM zone\n",
    "zone = 33\n",
    "southern_hemisphere = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# My data in UTM coordinates\n",
    "db_sar = pd.read_csv(folder_inout+'/'+synth_file)\n",
    "d_sar = db_sar.values\n",
    "\n",
    "# Split into east and north coordinates\n",
    "east, north = d_sar[:,0],d_sar[:,1]\n",
    "data = d_sar[:,3]\n",
    "synth = d_sar[:,2]\n",
    "res = data - synth\n",
    "\n",
    "dmax = max(max(data),max(synth))\n",
    "dmin = min(min(data),min(synth))\n",
    "resmax = max(res)\n",
    "resmin = min(res)\n",
    "resext = max(resmax, -resmin)\n",
    "\n",
    "# Define the projection\n",
    "#crs=ccrs.PlateCarree()\n",
    "mycrs=ccrs.UTM(zone=zone, southern_hemisphere=southern_hemisphere)\n",
    "\n",
    "fig=plt.figure(figsize=(15,6))\n",
    "\n",
    "## PANEL DATA ##########\n",
    "ax = plt.subplot(131, projection=mycrs)\n",
    "ax.coastlines(resolution='10m')\n",
    "img = ax.scatter(east, north,5, data, cmap=\"RdYlBu_r\", vmin=dmin, vmax = dmax)\n",
    "#palette\n",
    "cbar = plt.colorbar(img,orientation='horizontal')\n",
    "cbar.set_label('LOS (m)')\n",
    "# Get the extent of the axis\n",
    "extent = ax.get_extent()\n",
    "# Attempt to set the axis extent\n",
    "ax.set_extent(extent, crs=mycrs)\n",
    "plt.title('Data',fontsize = 16, pad=10)\n",
    "\n",
    "## PANEL MODEL ##########\n",
    "ax = plt.subplot(132, projection=mycrs)\n",
    "ax.coastlines(resolution='10m')\n",
    "img = ax.scatter(east, north,5, synth,cmap=\"RdYlBu_r\", vmin=dmin, vmax = dmax)\n",
    "#palette\n",
    "cbar = plt.colorbar(img,orientation='horizontal')\n",
    "cbar.set_label('LOS (m)')\n",
    "# Get the extent of the axis\n",
    "extent = ax.get_extent()\n",
    "# Attempt to set the axis extent\n",
    "ax.set_extent(extent, crs=mycrs)\n",
    "plt.title('Model',fontsize = 16, pad=10)\n",
    "\n",
    "## PANEL RESIDUALS ##########\n",
    "ax = plt.subplot(133, projection=mycrs)\n",
    "ax.coastlines(resolution='10m')\n",
    "img = ax.scatter(east, north,5, data - synth,cmap=\"bwr\",vmin=resext, vmax = -resext)\n",
    "#palette\n",
    "cbar = plt.colorbar(img,orientation='horizontal')\n",
    "cbar.set_label('LOS (m)')\n",
    "# Get the extent of the axis\n",
    "extent = ax.get_extent()\n",
    "# Attempt to set the axis extent\n",
    "ax.set_extent(extent, crs=mycrs)\n",
    "# Title for plot\n",
    "plt.title('Residual',fontsize = 16, pad=10)\n",
    "\n",
    "plt.savefig(folder_inout+'/'+out_file)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
